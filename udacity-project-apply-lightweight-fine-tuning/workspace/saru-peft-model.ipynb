{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f35354cd",
   "metadata": {},
   "source": [
    "# Lightweight Fine-Tuning Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560fb3ff",
   "metadata": {},
   "source": [
    "TODO: In this cell, describe your choices for each of the following\n",
    "\n",
    "* PEFT technique: LoRA (Low-Rank Adaptation)\n",
    "* Model: GPT-2 (via Hugging Face – 'gpt2')\n",
    "* Evaluation approach: Accuracy comparison before and after fine-tuning using Hugging Face `Trainer`\n",
    "* Fine-tuning dataset: 'ag_news' dataset from Hugging Face (for news classification, simple and fast) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8d76bb",
   "metadata": {},
   "source": [
    "## Loading and Evaluating a Foundation Model\n",
    "\n",
    "TODO: In the cells below, load your chosen pre-trained Hugging Face model and evaluate its performance prior to fine-tuning. This step includes loading an appropriate tokenizer and dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f551c63a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39d4cb799bd94698bdd6f1c3d19e7689",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/120000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f49e19c132ac4b07843cce072b073f6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04ddbf0894ed4b588c7ad39171c1f564",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [125/125 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original model performance: {'eval_loss': 5.43803596496582, 'eval_accuracy': 0.294, 'eval_runtime': 4.3991, 'eval_samples_per_second': 113.66, 'eval_steps_per_second': 28.415}\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "\n",
    "# Load dataset\n",
    "dataset = load_dataset(\"ag_news\")\n",
    "dataset = dataset.map(lambda x: {\"labels\": x[\"label\"]}, remove_columns=[\"label\"])\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "\n",
    "# Tokenize dataset\n",
    "def tokenize(example):\n",
    "    return tokenizer(example[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "\n",
    "tokenized_ds = dataset.map(tokenize, batched=True)\n",
    "tokenized_ds.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "# Load model for classification\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"gpt2\", num_labels=4)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "# Define metric\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {\"accuracy\": (predictions == labels).mean()}\n",
    "\n",
    "# Training arguments\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"/tmp/base_model\",\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=1,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    logging_dir=\"/tmp/logs\",\n",
    "    logging_steps=10,\n",
    "    save_total_limit=1\n",
    ")\n",
    "\n",
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_ds[\"train\"].select(range(2000)),\n",
    "    eval_dataset=tokenized_ds[\"test\"].select(range(500)),\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Evaluate base model\n",
    "original_results = trainer.evaluate()\n",
    "print(\"Original model performance:\", original_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4935cb4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28c4a78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019b9f55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5176b07f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d52a229",
   "metadata": {},
   "source": [
    "## Performing Parameter-Efficient Fine-Tuning\n",
    "\n",
    "TODO: In the cells below, create a PEFT model from your loaded model, run a training loop, and save the PEFT model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5775fadf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/peft/tuners/lora.py:475: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 817,152 || all params: 125,256,960 || trainable%: 0.6523805144241086\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 01:35, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.003900</td>\n",
       "      <td>0.907947</td>\n",
       "      <td>0.678000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.537200</td>\n",
       "      <td>0.614833</td>\n",
       "      <td>0.792000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('./peft_model/tokenizer_config.json',\n",
       " './peft_model/special_tokens_map.json',\n",
       " './peft_model/vocab.json',\n",
       " './peft_model/merges.txt',\n",
       " './peft_model/added_tokens.json',\n",
       " './peft_model/tokenizer.json')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "# Create LoRA config\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"c_attn\", \"c_proj\"],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_CLS\"\n",
    ")\n",
    "\n",
    "# Wrap base model in PEFT\n",
    "peft_model = get_peft_model(model, lora_config)\n",
    "peft_model.print_trainable_parameters()\n",
    "\n",
    "# Training arguments for PEFT\n",
    "peft_args = TrainingArguments(\n",
    "    output_dir=\"/tmp/peft_model\",\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=2,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"/tmp/peft_logs\",\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "# PEFT Trainer\n",
    "peft_trainer = Trainer(\n",
    "    model=peft_model,\n",
    "    args=peft_args,\n",
    "    train_dataset=tokenized_ds[\"train\"].select(range(2000)),\n",
    "    eval_dataset=tokenized_ds[\"test\"].select(range(500)),\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Train PEFT model\n",
    "peft_trainer.train()\n",
    "\n",
    "# Save PEFT adapter only\n",
    "peft_model.save_pretrained(\"/tmp/peft_model\")\n",
    "tokenizer.save_pretrained(\"/tmp/peft_model\")\n",
    "# Re-save to a directory next to the notebook\n",
    "peft_model.save_pretrained(\"./peft_model\")\n",
    "tokenizer.save_pretrained(\"./peft_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894046c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d4c908",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47abf88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7e8a663",
   "metadata": {},
   "source": [
    "###  ⚠️ IMPORTANT ⚠️\n",
    "\n",
    "Due to workspace storage constraints, you should not store the model weights in the same directory but rather use `/tmp` to avoid workspace crashes which are irrecoverable.\n",
    "Ensure you save it in /tmp always."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa7fe003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['adapter_model.bin', 'adapter_config.json', 'README.md', 'merges.txt', 'tokenizer.json', 'tokenizer_config.json', 'special_tokens_map.json', 'vocab.json']\n"
     ]
    }
   ],
   "source": [
    "# Saving the model\n",
    "# model.save(\"/tmp/peft-model\") - this is not working, already saved in previous step - check saved\n",
    "import os\n",
    "# Re-save to a directory next to the notebook\n",
    "peft_model.save_pretrained(\"./peft_model\")\n",
    "tokenizer.save_pretrained(\"./peft_model\")\n",
    "\n",
    "print(os.listdir(\"./peft_model\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615b12c6",
   "metadata": {},
   "source": [
    "## Performing Inference with a PEFT Model\n",
    "\n",
    "TODO: In the cells below, load the saved PEFT model weights and evaluate the performance of the trained PEFT model. Be sure to compare the results to the results from prior to fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "863ec66e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [125/125 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned PEFT model performance: {'eval_loss': 0.6148329973220825, 'eval_accuracy': 0.792, 'eval_runtime': 4.5294, 'eval_samples_per_second': 110.389, 'eval_steps_per_second': 27.597}\n",
      "\n",
      " Comparison:\n",
      "Original: {'eval_loss': 5.43803596496582, 'eval_accuracy': 0.294, 'eval_runtime': 4.3991, 'eval_samples_per_second': 113.66, 'eval_steps_per_second': 28.415}\n",
      "PEFT Fine-tuned: {'eval_loss': 0.6148329973220825, 'eval_accuracy': 0.792, 'eval_runtime': 4.5294, 'eval_samples_per_second': 110.389, 'eval_steps_per_second': 27.597}\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer\n",
    "from peft import PeftModel, PeftConfig\n",
    "\n",
    "# 1. Load PEFT config\n",
    "peft_config = PeftConfig.from_pretrained(\"./peft_model\")\n",
    "\n",
    "# 2. Load tokenizer (with pad token fix)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./peft_model\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# 3. Load base model\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    peft_config.base_model_name_or_path,\n",
    "    num_labels=4\n",
    ")\n",
    "base_model.config.pad_token_id = tokenizer.pad_token_id\n",
    "base_model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# 4. Load adapter weights\n",
    "peft_loaded = PeftModel.from_pretrained(base_model, \"./peft_model\")\n",
    "peft_loaded.eval()\n",
    "\n",
    "# 5. Re-evaluate using Trainer\n",
    "peft_eval_trainer = Trainer(\n",
    "    model=peft_loaded,\n",
    "    args=args,\n",
    "    eval_dataset=tokenized_ds[\"test\"].select(range(500)),\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# 6. Evaluate and compare\n",
    "peft_results = peft_eval_trainer.evaluate()\n",
    "print(\"Fine-tuned PEFT model performance:\", peft_results)\n",
    "\n",
    "# 7. Compare with original\n",
    "print(\"\\n Comparison:\")\n",
    "print(\"Original:\", original_results)\n",
    "print(\"PEFT Fine-tuned:\", peft_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc3a8147",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 817,152 || all params: 125,256,960 || trainable%: 0.6523805144241086\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. Try using the bitsandbytes package (installed in the workspace) to combine quantization and LoRA. This is also known as QLoRA\n",
    "\n",
    "from transformers import BitsAndBytesConfig, AutoModelForSequenceClassification\n",
    "from peft import get_peft_model, LoraConfig\n",
    "import torch\n",
    "\n",
    "\n",
    "# Quantization config\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    ")\n",
    "\n",
    "# Load quantized model (4-bit GPT-2 with correct num_labels)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"gpt2\",\n",
    "    num_labels=4,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# LoRA config\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"c_attn\", \"c_proj\"],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_CLS\"\n",
    ")\n",
    "\n",
    "# Merge quantization + LoRA = QLoRA\n",
    "qlora_model = get_peft_model(model, lora_config)\n",
    "qlora_model.print_trainable_parameters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc96905a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 405,504 || all params: 124,851,456 || trainable%: 0.3247891638524424\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 00:49, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.554900</td>\n",
       "      <td>1.734725</td>\n",
       "      <td>0.288000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [125/125 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for r=4, alpha=8: {'eval_loss': 1.7347248792648315, 'eval_accuracy': 0.288, 'eval_runtime': 4.7637, 'eval_samples_per_second': 104.961, 'eval_steps_per_second': 26.24, 'epoch': 1.0}\n",
      "trainable params: 811,008 || all params: 125,256,960 || trainable%: 0.6474753977743033\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 00:50, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.406900</td>\n",
       "      <td>1.557835</td>\n",
       "      <td>0.336000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory /tmp/base_model/checkpoint-500 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [125/125 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for r=8, alpha=16: {'eval_loss': 1.5578352212905884, 'eval_accuracy': 0.336, 'eval_runtime': 4.7283, 'eval_samples_per_second': 105.746, 'eval_steps_per_second': 26.437, 'epoch': 1.0}\n",
      "trainable params: 1,622,016 || all params: 126,067,968 || trainable%: 1.2866202459930187\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 00:51, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.248900</td>\n",
       "      <td>1.376761</td>\n",
       "      <td>0.410000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory /tmp/base_model/checkpoint-500 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [125/125 00:46]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for r=16, alpha=32: {'eval_loss': 1.3767609596252441, 'eval_accuracy': 0.41, 'eval_runtime': 4.8188, 'eval_samples_per_second': 103.76, 'eval_steps_per_second': 25.94, 'epoch': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# 2. Try training the model using different PEFT configurations and compare the results\n",
    "\n",
    "configs_to_try = [\n",
    "    {\"r\": 4, \"alpha\": 8},\n",
    "    {\"r\": 8, \"alpha\": 16},\n",
    "    {\"r\": 16, \"alpha\": 32}\n",
    "]\n",
    "\n",
    "for cfg in configs_to_try:\n",
    "    lora_config = LoraConfig(\n",
    "        r=cfg[\"r\"],\n",
    "        lora_alpha=cfg[\"alpha\"],\n",
    "        target_modules=[\"c_attn\", \"c_proj\"],\n",
    "        lora_dropout=0.1,\n",
    "        bias=\"none\",\n",
    "        task_type=\"SEQ_CLS\"\n",
    "    )\n",
    "    \n",
    "    model = get_peft_model(base_model, lora_config)\n",
    "    model.print_trainable_parameters()\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=args,\n",
    "        train_dataset=tokenized_ds[\"train\"].select(range(2000)),\n",
    "        eval_dataset=tokenized_ds[\"test\"].select(range(500)),\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    results = trainer.evaluate()\n",
    "    print(f\"Results for r={cfg['r']}, alpha={cfg['alpha']}: {results}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "866ab28c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary of LoRA Config Results:\n",
      "r=4, alpha=8 => Accuracy: 0.410\n",
      "r=8, alpha=16 => Accuracy: 0.410\n",
      "r=16, alpha=32 => Accuracy: 0.410\n"
     ]
    }
   ],
   "source": [
    "all_results = []\n",
    "\n",
    "for cfg in configs_to_try:\n",
    "    ...\n",
    "    result = trainer.evaluate()\n",
    "    all_results.append((cfg[\"r\"], cfg[\"alpha\"], result[\"eval_accuracy\"]))\n",
    "\n",
    "print(\"\\nSummary of LoRA Config Results:\")\n",
    "for r, alpha, acc in all_results:\n",
    "    print(f\"r={r}, alpha={alpha} => Accuracy: {acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a32e4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
